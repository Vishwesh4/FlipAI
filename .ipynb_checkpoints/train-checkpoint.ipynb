{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from core.model import BBregression\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "import scipy.io\n",
    "import scipy.misc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from core.Dataloader import Dataloader\n",
    "import cv2\n",
    "import random\n",
    "from tensorflow.keras import backend as K\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 480, 480, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 480, 480, 16)      432       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 480, 480, 16)      64        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)      (None, 480, 480, 16)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 240, 240, 16)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 240, 240, 32)      4608      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 240, 240, 32)      128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 240, 240, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 120, 120, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 120, 120, 64)      18432     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 120, 120, 64)      256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 120, 120, 64)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 60, 60, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 60, 60, 128)       73728     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 60, 60, 128)       512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 60, 60, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 30, 30, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 30, 30, 256)       294912    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 30, 30, 256)       1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 30, 30, 256)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 15, 15, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 15, 15, 256)       589824    \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 15, 15, 256)       1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 15, 15, 256)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 15, 15, 256)       0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 57600)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4)                 230404    \n",
      "=================================================================\n",
      "Total params: 1,215,348\n",
      "Trainable params: 1,213,844\n",
      "Non-trainable params: 1,504\n",
      "_________________________________________________________________\n",
      "[Model] Model Compiled\n"
     ]
    }
   ],
   "source": [
    "model = BBregression(480)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('./Data/df_train.csv',index_col=0)\n",
    "df_test = pd.read_csv('./Data/df_test.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y1</th>\n",
       "      <th>y2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./images/JPEG_20161123_170503_100079195103.png</td>\n",
       "      <td>0.279687</td>\n",
       "      <td>0.871875</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>./images/JPEG_20161202_162219_1000699486504.png</td>\n",
       "      <td>0.151562</td>\n",
       "      <td>0.945312</td>\n",
       "      <td>0.285417</td>\n",
       "      <td>0.804167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>./images/1474630452246DSC08185.png</td>\n",
       "      <td>0.121875</td>\n",
       "      <td>0.934375</td>\n",
       "      <td>0.122917</td>\n",
       "      <td>0.906250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>./images/147771751685420161028_142932.png</td>\n",
       "      <td>0.151562</td>\n",
       "      <td>0.762500</td>\n",
       "      <td>0.179167</td>\n",
       "      <td>0.816667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>./images/JPEG_20160607_163726_1000799717730.png</td>\n",
       "      <td>0.246875</td>\n",
       "      <td>0.773438</td>\n",
       "      <td>0.043750</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        image_name        x1        x2  \\\n",
       "0   ./images/JPEG_20161123_170503_100079195103.png  0.279687  0.871875   \n",
       "1  ./images/JPEG_20161202_162219_1000699486504.png  0.151562  0.945312   \n",
       "2               ./images/1474630452246DSC08185.png  0.121875  0.934375   \n",
       "3        ./images/147771751685420161028_142932.png  0.151562  0.762500   \n",
       "4  ./images/JPEG_20160607_163726_1000799717730.png  0.246875  0.773438   \n",
       "\n",
       "         y1        y2  \n",
       "0  0.416667  0.500000  \n",
       "1  0.285417  0.804167  \n",
       "2  0.122917  0.906250  \n",
       "3  0.179167  0.816667  \n",
       "4  0.043750  1.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0  Losses: 0.26673585\n",
      "Epoch: 0  Losses: 0.21253972\n",
      "Epoch: 0  Losses: 0.20611414\n"
     ]
    }
   ],
   "source": [
    "# data = Dataloader(df=df_train)\n",
    "# labels = tf.placeholder(tf.float32, shape=(None, 4))\n",
    "# generator = data.build_iterator()\n",
    "\n",
    "# losses = tf.losses.mean_squared_error(labels,model.m.output)\n",
    "\n",
    "# train_step = tf.train.AdamOptimizer(0.0001).minimize(losses)\n",
    "# with tf.Session() as sess:\n",
    "#     sess.run(tf.global_variables_initializer())\n",
    "#     for epochs in range(10):\n",
    "#         for batches in range(12000/64):\n",
    "#             batch = generator.get_next()\n",
    "#             train_data= sess.run(batch)\n",
    "#             _,loss = sess.run([train_step,losses],feed_dict={model.m.input: train_data[0],labels: train_data[1]})\n",
    "#             print \"Epoch:\",epochs,\" Losses:\",loss\n",
    "#         model.m.save(\"./saved_models/model_saved\")    \n",
    "# acc_value = accuracy(labels, preds)\n",
    "# with sess.as_default():\n",
    "#     print acc_value.eval(feed_dict={img: mnist_data.test.images,\n",
    "#                                     labels: mnist_data.test.labels,\n",
    "#                                     K.learning_phase(): 0})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Model] Training Started\n",
      "[Model] 10 epochs, 64 batch size, 187 batches per epoch\n",
      "Epoch 1/10\n",
      "187/187 [==============================] - 36414s 195s/step - loss: 0.4745 - acc: 0.5367: 12:28:01 - loss: 0.7058 - - ETA: 6:27:54 - loss:  - ETA: 5:11:47 - loss: 0.6692 - acc - ETA: 4:54:06 - loss: 0.6626 - acc: 0.52 - ETA: 4:50:00 - loss: 0. - ETA: 4:46:30 - loss: 0.6452 - acc: 0. - ETA: 4:42:33 -  - ETA: 4:27:03 - loss: 0.6202 - acc: 0.52 - ETA: 4:31:32 - loss: 0.6185 - acc - ETA: 4:31:29 - loss: 0.6118 - - ETA: 4:28:3 - ETA: 4:10:19 - lo - ETA: 3:48:29 - loss: 0.5664 - acc: 0. - ETA: 3:45:18 - loss: 0.5640 - ETA: 3:34:32 - loss: 0.5560 - acc - ETA: 3:28:42 - loss: 0.5513 - acc: 0.53 - ETA: 3:26:59 - loss: 0.5503 - acc:  - ETA: 3:22:03 - loss: 0.5470 - acc: 0.53 - ETA: 3:20:32 - loss: 0.5459 - acc: 0.53 - ETA: 3:18:34 - loss: 0.5448 - - ETA: 2:25:37 - loss: 0.5168 - a - ETA: 2:13:53 - loss: 0.5124 - - ETA: 1:59:52 - loss: 0.5074 - acc: 0.53 - ETA: 1:57:28 - loss: 0.5065 - - ETA - ETA: 50:34 - loss: 0.4862 - acc: 0.53 - ETA: 47:24 -\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "ename": "UnknownError",
     "evalue": "exceptions.IndexError: single positional indexer is out-of-bounds\nTraceback (most recent call last):\n\n  File \"/home/vishwesh/anaconda3/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/ops/script_ops.py\", line 206, in __call__\n    ret = func(*args)\n\n  File \"/home/vishwesh/anaconda3/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 451, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"core/Dataloader.py\", line 13, in generator\n    img_path,bx,by,bh,bw = self.df.iloc[i]\n\n  File \"/home/vishwesh/anaconda3/envs/tensorflow/lib/python2.7/site-packages/pandas/core/indexing.py\", line 1373, in __getitem__\n    return self._getitem_axis(maybe_callable, axis=axis)\n\n  File \"/home/vishwesh/anaconda3/envs/tensorflow/lib/python2.7/site-packages/pandas/core/indexing.py\", line 1830, in _getitem_axis\n    self._is_valid_integer(key, axis)\n\n  File \"/home/vishwesh/anaconda3/envs/tensorflow/lib/python2.7/site-packages/pandas/core/indexing.py\", line 1713, in _is_valid_integer\n    raise IndexError(\"single positional indexer is out-of-bounds\")\n\nIndexError: single positional indexer is out-of-bounds\n\n\n\t [[{{node PyFunc}} = PyFunc[Tin=[DT_INT64], Tout=[DT_STRING, DT_FLOAT], token=\"pyfunc_7\"](arg0)]]\n\t [[{{node IteratorGetNext_2}} = IteratorGetNext[output_shapes=[[?,480,480,3], [?,?]], output_types=[DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](OneShotIterator_2)]]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-c2dc4b5e03cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0msave_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"./saved_models\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m )\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/vishwesh/Projects/Machine Learning/Flipkart_challenge/core/model.py\u001b[0m in \u001b[0;36mtrain_generator\u001b[0;34m(self, data_gen, epochs, batch_size, steps_per_epoch, save_dir)\u001b[0m\n\u001b[1;32m     85\u001b[0m             \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         )\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/vishwesh/anaconda3/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1637\u001b[0m           \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1638\u001b[0m           \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1639\u001b[0;31m           validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1641\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m/home/vishwesh/anaconda3/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/keras/engine/training_arrays.pyc\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m           \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m           logging.warning('Your dataset iterator ran out of data; '\n",
      "\u001b[0;32m/home/vishwesh/anaconda3/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/keras/backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2984\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2985\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 2986\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   2987\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2988\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/vishwesh/anaconda3/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/vishwesh/anaconda3/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/framework/errors_impl.pyc\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    526\u001b[0m             \u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 528\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    529\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m     \u001b[0;31m# as there is a reference to status from this from the traceback due to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnknownError\u001b[0m: exceptions.IndexError: single positional indexer is out-of-bounds\nTraceback (most recent call last):\n\n  File \"/home/vishwesh/anaconda3/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/ops/script_ops.py\", line 206, in __call__\n    ret = func(*args)\n\n  File \"/home/vishwesh/anaconda3/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 451, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"core/Dataloader.py\", line 13, in generator\n    img_path,bx,by,bh,bw = self.df.iloc[i]\n\n  File \"/home/vishwesh/anaconda3/envs/tensorflow/lib/python2.7/site-packages/pandas/core/indexing.py\", line 1373, in __getitem__\n    return self._getitem_axis(maybe_callable, axis=axis)\n\n  File \"/home/vishwesh/anaconda3/envs/tensorflow/lib/python2.7/site-packages/pandas/core/indexing.py\", line 1830, in _getitem_axis\n    self._is_valid_integer(key, axis)\n\n  File \"/home/vishwesh/anaconda3/envs/tensorflow/lib/python2.7/site-packages/pandas/core/indexing.py\", line 1713, in _is_valid_integer\n    raise IndexError(\"single positional indexer is out-of-bounds\")\n\nIndexError: single positional indexer is out-of-bounds\n\n\n\t [[{{node PyFunc}} = PyFunc[Tin=[DT_INT64], Tout=[DT_STRING, DT_FLOAT], token=\"pyfunc_7\"](arg0)]]\n\t [[{{node IteratorGetNext_2}} = IteratorGetNext[output_shapes=[[?,480,480,3], [?,?]], output_types=[DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](OneShotIterator_2)]]"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "data = Dataloader(df=df_train)\n",
    "\n",
    "# model = BBregression(480)\n",
    "model.m.load_weights('./saved_models/12022019-080837-e10.h5')\n",
    "\n",
    "    # out-of memory generative training\n",
    "steps_per_epoch = math.ceil((12000) // 64)\n",
    "model.train_generator(\n",
    "data_gen=data.build_iterator(),\n",
    "    epochs=10,\n",
    "    batch_size=64,\n",
    "    steps_per_epoch=int(steps_per_epoch),\n",
    "    save_dir=\"./saved_models\"\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y1</th>\n",
       "      <th>y2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1474723840903DSC08089.png</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1473231475010DeeplearnS11276.png</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>JPEG_20161205_135307_1000155917326.png</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>JPEG_20160711_123440_1000518778437.png</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>JPEG_20160803_115329_100034020722.png</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               image_name  x1  x2  y1  y2\n",
       "0               1474723840903DSC08089.png NaN NaN NaN NaN\n",
       "1        1473231475010DeeplearnS11276.png NaN NaN NaN NaN\n",
       "2  JPEG_20161205_135307_1000155917326.png NaN NaN NaN NaN\n",
       "3  JPEG_20160711_123440_1000518778437.png NaN NaN NaN NaN\n",
       "4   JPEG_20160803_115329_100034020722.png NaN NaN NaN NaN"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Predictions\n",
    "df_pred = pd.read_csv(\"./Data/test.csv\")\n",
    "df_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_prediction=df_pred.copy()\n",
    "def value_updater(df,pred):\n",
    "    for i in range(64):\n",
    "        df['x1'].iloc[i] = pred[i,0]*640\n",
    "        df['x2'].iloc[i] = pred[i,1]*640\n",
    "        df['y1'].iloc[i] = pred[i,2]*480\n",
    "        df['y2'].iloc[i] = pred[i,3]*480\n",
    "    return df        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "global name 'df_training' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-0e5583842ddf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mgenerator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mdf_prediction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalue_updater\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_prediction\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mbatches\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m12815\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-bdae8418470b>\u001b[0m in \u001b[0;36mvalue_updater\u001b[0;34m(df, pred)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mvalue_updater\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0mdf_training\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'x1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m640\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0mdf_training\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'x2'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m640\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mdf_training\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'y1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m480\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: global name 'df_training' is not defined"
     ]
    }
   ],
   "source": [
    "data = Dataloader(df=df_pred)\n",
    "# labels = tf.placeholder(tf.float32, shape=(None, 4))\n",
    "model.m.load_weights('./saved_models/12022019-115700-e10.h5')\n",
    "generator = data.build_iterator()\n",
    "prediction = []\n",
    "df_prediction=value_updater(df_prediction,model.m.output)\n",
    "with tf.Session() as sess:            \n",
    "    for batches in range(int(12815//64)):\n",
    "        batch = generator.get_next()\n",
    "        test_images,_= sess.run(batch)\n",
    "        _ = sess.run([df_prediction],feed_dict={model.m.input: train_data[0]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b = [[3,4],[4,5]]\n",
    "c = [[3,2],[1,4]]\n",
    "k = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k.extend(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "k.extend(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 4, 3, 2, 3, 4]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
